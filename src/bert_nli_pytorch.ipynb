{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BHqpAXipTH-B",
        "x9_msVLYTH-C"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xlmN_2TH95"
      },
      "source": [
        "# Setting Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6eOgkbETM4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b76431-9774-48b8-a538-e9a98c07e21e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:36.396454Z",
          "iopub.execute_input": "2021-05-22T18:22:36.396768Z",
          "iopub.status.idle": "2021-05-22T18:22:36.412405Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.396741Z",
          "shell.execute_reply": "2021-05-22T18:22:36.411362Z"
        },
        "trusted": true,
        "id": "ZYRlkywfTH98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04c2d79-db24-40b0-e090-efaa5e0eaa50"
      },
      "source": [
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyqsMcL6TH98"
      },
      "source": [
        "# Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:36.413926Z",
          "iopub.execute_input": "2021-05-22T18:22:36.414320Z",
          "iopub.status.idle": "2021-05-22T18:22:36.738700Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.414279Z",
          "shell.execute_reply": "2021-05-22T18:22:36.737913Z"
        },
        "trusted": true,
        "id": "jUiwn5QfTH99"
      },
      "source": [
        "import torch\n",
        "\n",
        "SEED = 1111\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:36.741101Z",
          "iopub.execute_input": "2021-05-22T18:22:36.741342Z",
          "iopub.status.idle": "2021-05-22T18:22:39.816045Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.741317Z",
          "shell.execute_reply": "2021-05-22T18:22:39.815184Z"
        },
        "trusted": true,
        "id": "A6fmllOKTH99"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.847826Z",
          "iopub.execute_input": "2021-05-22T18:22:39.848458Z",
          "iopub.status.idle": "2021-05-22T18:22:39.856324Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.848417Z",
          "shell.execute_reply": "2021-05-22T18:22:39.855337Z"
        },
        "trusted": true,
        "id": "dmwYflD8TH9-",
        "outputId": "a04a0a86-1385-4431-a4ad-196afffc5100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.857905Z",
          "iopub.execute_input": "2021-05-22T18:22:39.858605Z",
          "iopub.status.idle": "2021-05-22T18:22:39.865416Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.858568Z",
          "shell.execute_reply": "2021-05-22T18:22:39.864368Z"
        },
        "trusted": true,
        "id": "qUcbVwr2TH9_",
        "outputId": "feffaf58-21aa-48eb-d131-6725060e1e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 102 0 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.866788Z",
          "iopub.execute_input": "2021-05-22T18:22:39.867411Z",
          "iopub.status.idle": "2021-05-22T18:22:39.875804Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.867372Z",
          "shell.execute_reply": "2021-05-22T18:22:39.874848Z"
        },
        "trusted": true,
        "id": "fHo--jhxTH9_",
        "outputId": "165e1e88-fdff-4446-aa57-e749f588982f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)\n",
        "\n",
        "max_input_length = 63"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.877189Z",
          "iopub.execute_input": "2021-05-22T18:22:39.877717Z",
          "iopub.status.idle": "2021-05-22T18:22:39.884514Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.877674Z",
          "shell.execute_reply": "2021-05-22T18:22:39.883641Z"
        },
        "trusted": true,
        "id": "83VWXLVLTH-A"
      },
      "source": [
        "def tokenize_bert(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    return tokens"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.885989Z",
          "iopub.execute_input": "2021-05-22T18:22:39.886398Z",
          "iopub.status.idle": "2021-05-22T18:22:39.894256Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.886361Z",
          "shell.execute_reply": "2021-05-22T18:22:39.893338Z"
        },
        "trusted": true,
        "id": "DYvGYvORTH-A"
      },
      "source": [
        "def split_and_cut(sentence):\n",
        "    tokens = sentence.strip().split(\" \")\n",
        "    tokens = tokens[:max_input_length-1]\n",
        "    return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.895637Z",
          "iopub.execute_input": "2021-05-22T18:22:39.896302Z",
          "iopub.status.idle": "2021-05-22T18:22:39.904166Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.896263Z",
          "shell.execute_reply": "2021-05-22T18:22:39.903403Z"
        },
        "trusted": true,
        "id": "6K4QtCsQTH-A"
      },
      "source": [
        "def trim_sentence(sent):\n",
        "    try:\n",
        "        sent = sent.split()\n",
        "        sent = sent[:32]\n",
        "        return \" \".join(sent)\n",
        "    except:\n",
        "        return sent"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHqpAXipTH-B"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:39.905621Z",
          "iopub.execute_input": "2021-05-22T18:22:39.906075Z",
          "iopub.status.idle": "2021-05-22T18:22:51.266832Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.906039Z",
          "shell.execute_reply": "2021-05-22T18:22:51.265794Z"
        },
        "trusted": true,
        "id": "GI2wzJciTH-B",
        "outputId": "3108aa30-5d76-40df-9abc-a5b157dfd898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-05 15:18:14--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip.1’\n",
            "\n",
            "snli_1.0.zip.1      100%[===================>]  90.17M  19.8MB/s    in 7.6s    \n",
            "\n",
            "2023-05-05 15:18:22 (11.8 MB/s) - ‘snli_1.0.zip.1’ saved [94550081/94550081]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:51.269742Z",
          "iopub.execute_input": "2021-05-22T18:22:51.270159Z",
          "iopub.status.idle": "2021-05-22T18:22:54.896800Z",
          "shell.execute_reply.started": "2021-05-22T18:22:51.270112Z",
          "shell.execute_reply": "2021-05-22T18:22:54.895335Z"
        },
        "trusted": true,
        "id": "hclFoPKmTH-B",
        "outputId": "8462e08c-309b-496e-e78f-73b08bba9d2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "# specifying the zip file name\n",
        "file_name = \"snli_1.0.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "  \n",
        "    # extracting all the files\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "snli_1.0/                                      2015-08-29 08:57:10            0\n",
            "snli_1.0/.DS_Store                             2015-08-29 08:57:16         6148\n",
            "__MACOSX/                                      2015-08-29 09:00:04            0\n",
            "__MACOSX/snli_1.0/                             2015-08-29 09:00:04            0\n",
            "__MACOSX/snli_1.0/._.DS_Store                  2015-08-29 08:57:16          120\n",
            "snli_1.0/Icon\r                                 2015-05-21 16:21:08            0\n",
            "__MACOSX/snli_1.0/._Icon\r                      2015-05-21 16:21:08       340709\n",
            "snli_1.0/README.txt                            2015-08-29 08:59:48         5828\n",
            "__MACOSX/snli_1.0/._README.txt                 2015-08-29 08:59:48          171\n",
            "snli_1.0/snli_1.0_dev.jsonl                    2015-08-17 10:34:22      9745714\n",
            "snli_1.0/snli_1.0_dev.txt                      2015-08-17 10:34:24      7565773\n",
            "snli_1.0/snli_1.0_test.jsonl                   2015-08-17 10:34:26      9730457\n",
            "snli_1.0/snli_1.0_test.txt                     2015-08-17 10:34:28      7550390\n",
            "snli_1.0/snli_1.0_train.jsonl                  2015-08-17 10:34:52    487457790\n",
            "snli_1.0/snli_1.0_train.txt                    2015-08-17 10:35:12    375697923\n",
            "__MACOSX/._snli_1.0                            2015-08-29 08:57:10          120\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9_msVLYTH-C"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:22:54.898199Z",
          "iopub.execute_input": "2021-05-22T18:22:54.898549Z",
          "iopub.status.idle": "2021-05-22T18:22:54.904679Z",
          "shell.execute_reply.started": "2021-05-22T18:22:54.898514Z",
          "shell.execute_reply": "2021-05-22T18:22:54.903657Z"
        },
        "trusted": true,
        "id": "J1lTSBY2TH-C"
      },
      "source": [
        "def get_sent1_token_type(sent):\n",
        "    try:\n",
        "        return [0]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def get_sent2_token_type(sent):\n",
        "    try:\n",
        "        return [1]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "    \n",
        "def combine_seq(seq):\n",
        "    return \" \".join(seq)\n",
        "\n",
        "def combine_mask(mask):\n",
        "    mask = [str(m) for m in mask]\n",
        "    return \" \".join(mask)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_OB1lsTowj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7ef6ed-0988-4cda-e54b-5501bfda523c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('snli_1.0/snli_1.0_train.txt', sep='\\t')\n",
        "df_dev = pd.read_csv('snli_1.0/snli_1.0_dev.txt', sep='\\t')\n",
        "df_test = pd.read_csv('snli_1.0/snli_1.0_test.txt', sep='\\t')\n",
        "\n",
        "df_train = df_train[['gold_label','sentence1','sentence2']]\n",
        "df_dev = df_dev[['gold_label','sentence1','sentence2']]\n",
        "df_test = df_test[['gold_label','sentence1','sentence2']]\n",
        "\n",
        "df_train = df_train[:40000]\n",
        "df_dev = df_train[:4000]\n",
        "df_test = df_train[:4000]\n",
        "\n",
        "\n",
        "df_train['sentence1'] = df_train['sentence1'].apply(trim_sentence)\n",
        "df_train['sentence2'] = df_train['sentence2'].apply(trim_sentence)\n",
        "df_dev['sentence1'] = df_dev['sentence1'].apply(trim_sentence)\n",
        "df_dev['sentence2'] = df_dev['sentence2'].apply(trim_sentence)\n",
        "df_test['sentence1'] = df_test['sentence1'].apply(trim_sentence)\n",
        "df_test['sentence2'] = df_test['sentence2'].apply(trim_sentence)\n",
        "\n",
        "df_train['sent1'] = '[CLS] ' + df_train['sentence1'] + ' [SEP] '\n",
        "df_train['sent2'] = df_train['sentence2'] + ' [SEP]'\n",
        "df_dev['sent1'] = '[CLS] ' + df_dev['sentence1'] + ' [SEP] '\n",
        "df_dev['sent2'] = df_dev['sentence2'] + ' [SEP]'\n",
        "df_test['sent1'] = '[CLS] ' + df_test['sentence1'] + ' [SEP] '\n",
        "df_test['sent2'] = df_test['sentence2'] + ' [SEP]'\n",
        "\n",
        "df_train['sent1_t'] = df_train['sent1'].apply(tokenize_bert)\n",
        "df_train['sent2_t'] = df_train['sent2'].apply(tokenize_bert)\n",
        "df_dev['sent1_t'] = df_dev['sent1'].apply(tokenize_bert)\n",
        "df_dev['sent2_t'] = df_dev['sent2'].apply(tokenize_bert)\n",
        "df_test['sent1_t'] = df_test['sent1'].apply(tokenize_bert)\n",
        "df_test['sent2_t'] = df_test['sent2'].apply(tokenize_bert)\n",
        "\n",
        "df_train['sent1_token_type'] = df_train['sent1_t'].apply(get_sent1_token_type)\n",
        "df_train['sent2_token_type'] = df_train['sent2_t'].apply(get_sent2_token_type)\n",
        "df_dev['sent1_token_type'] = df_dev['sent1_t'].apply(get_sent1_token_type)\n",
        "df_dev['sent2_token_type'] = df_dev['sent2_t'].apply(get_sent2_token_type)\n",
        "df_test['sent1_token_type'] = df_test['sent1_t'].apply(get_sent1_token_type)\n",
        "df_test['sent2_token_type'] = df_test['sent2_t'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['sequence'] = df_train['sent1_t'] + df_train['sent2_t']\n",
        "df_dev['sequence'] = df_dev['sent1_t'] + df_dev['sent2_t']\n",
        "df_test['sequence'] = df_test['sent1_t'] + df_test['sent2_t']\n",
        "\n",
        "\n",
        "df_train['attention_mask'] = df_train['sequence'].apply(get_sent2_token_type)\n",
        "df_dev['attention_mask'] = df_dev['sequence'].apply(get_sent2_token_type)\n",
        "df_test['attention_mask'] = df_test['sequence'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['token_type'] = df_train['sent1_token_type'] + df_train['sent2_token_type']\n",
        "df_dev['token_type'] = df_dev['sent1_token_type'] + df_dev['sent2_token_type']\n",
        "df_test['token_type'] = df_test['sent1_token_type'] + df_test['sent2_token_type']\n",
        "\n",
        "df_train['sequence'] = df_train['sequence'].apply(combine_seq)\n",
        "df_dev['sequence'] = df_dev['sequence'].apply(combine_seq)\n",
        "df_test['sequence'] = df_test['sequence'].apply(combine_seq)\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(combine_mask)\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].apply(combine_mask)\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
        "df_test['token_type'] = df_test['token_type'].apply(combine_mask)\n",
        "\n",
        "df_train = df_train[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_dev = df_dev[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_test = df_test[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "\n",
        "\n",
        "\n",
        "df_train = df_train.loc[df_train['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "df_dev = df_dev.loc[df_dev['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "df_test = df_test.loc[df_test['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "\n",
        "\n",
        "\n",
        "df_train.to_csv('snli_1.0/snli_1.0_train.csv', index=False)\n",
        "df_dev.to_csv('snli_1.0/snli_1.0_dev.csv', index=False)\n",
        "df_test.to_csv('snli_1.0/snli_1.0_test.csv', index=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-6aff7aca644c>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sentence1'] = df_dev['sentence1'].apply(trim_sentence)\n",
            "<ipython-input-21-6aff7aca644c>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sentence2'] = df_dev['sentence2'].apply(trim_sentence)\n",
            "<ipython-input-21-6aff7aca644c>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sentence1'] = df_test['sentence1'].apply(trim_sentence)\n",
            "<ipython-input-21-6aff7aca644c>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sentence2'] = df_test['sentence2'].apply(trim_sentence)\n",
            "<ipython-input-21-6aff7aca644c>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent1'] = '[CLS] ' + df_dev['sentence1'] + ' [SEP] '\n",
            "<ipython-input-21-6aff7aca644c>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent2'] = df_dev['sentence2'] + ' [SEP]'\n",
            "<ipython-input-21-6aff7aca644c>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent1'] = '[CLS] ' + df_test['sentence1'] + ' [SEP] '\n",
            "<ipython-input-21-6aff7aca644c>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent2'] = df_test['sentence2'] + ' [SEP]'\n",
            "<ipython-input-21-6aff7aca644c>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent1_t'] = df_dev['sent1'].apply(tokenize_bert)\n",
            "<ipython-input-21-6aff7aca644c>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent2_t'] = df_dev['sent2'].apply(tokenize_bert)\n",
            "<ipython-input-21-6aff7aca644c>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent1_t'] = df_test['sent1'].apply(tokenize_bert)\n",
            "<ipython-input-21-6aff7aca644c>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent2_t'] = df_test['sent2'].apply(tokenize_bert)\n",
            "<ipython-input-21-6aff7aca644c>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent1_token_type'] = df_dev['sent1_t'].apply(get_sent1_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sent2_token_type'] = df_dev['sent2_t'].apply(get_sent2_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent1_token_type'] = df_test['sent1_t'].apply(get_sent1_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sent2_token_type'] = df_test['sent2_t'].apply(get_sent2_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sequence'] = df_dev['sent1_t'] + df_dev['sent2_t']\n",
            "<ipython-input-21-6aff7aca644c>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sequence'] = df_test['sent1_t'] + df_test['sent2_t']\n",
            "<ipython-input-21-6aff7aca644c>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['attention_mask'] = df_dev['sequence'].apply(get_sent2_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['attention_mask'] = df_test['sequence'].apply(get_sent2_token_type)\n",
            "<ipython-input-21-6aff7aca644c>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['token_type'] = df_dev['sent1_token_type'] + df_dev['sent2_token_type']\n",
            "<ipython-input-21-6aff7aca644c>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['token_type'] = df_test['sent1_token_type'] + df_test['sent2_token_type']\n",
            "<ipython-input-21-6aff7aca644c>:58: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['sequence'] = df_dev['sequence'].apply(combine_seq)\n",
            "<ipython-input-21-6aff7aca644c>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['sequence'] = df_test['sequence'].apply(combine_seq)\n",
            "<ipython-input-21-6aff7aca644c>:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
            "<ipython-input-21-6aff7aca644c>:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
            "<ipython-input-21-6aff7aca644c>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
            "<ipython-input-21-6aff7aca644c>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['token_type'] = df_test['token_type'].apply(combine_mask)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:05.516834Z",
          "iopub.execute_input": "2021-05-22T18:24:05.517130Z",
          "iopub.status.idle": "2021-05-22T18:24:05.523940Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.517103Z",
          "shell.execute_reply": "2021-05-22T18:24:05.523027Z"
        },
        "trusted": true,
        "id": "Lmiw-NSBTH-F",
        "outputId": "ec52fbbb-07f2-4eac-b564-b358f126c9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df_train.iloc[0]['sequence'])\n",
        "print(df_train.iloc[0]['attention_mask'])\n",
        "print(df_train.iloc[0]['token_type'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] a person on a horse jumps over a broken down airplane . [SEP] a person is training his horse for a competition . [SEP]\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:05.547967Z",
          "iopub.execute_input": "2021-05-22T18:24:05.548321Z",
          "iopub.status.idle": "2021-05-22T18:24:05.553413Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.548287Z",
          "shell.execute_reply": "2021-05-22T18:24:05.552328Z"
        },
        "trusted": true,
        "id": "LoERk9gXTH-G"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:05.571467Z",
          "iopub.execute_input": "2021-05-22T18:24:05.572040Z",
          "iopub.status.idle": "2021-05-22T18:24:05.582200Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.571999Z",
          "shell.execute_reply": "2021-05-22T18:24:05.581378Z"
        },
        "trusted": true,
        "id": "jRapwGZtTH-H"
      },
      "source": [
        "def convert_to_int(tok_ids):\n",
        "    tok_ids = [int(x) for x in tok_ids]\n",
        "    return tok_ids"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:05.584732Z",
          "iopub.execute_input": "2021-05-22T18:24:05.585410Z",
          "iopub.status.idle": "2021-05-22T18:24:05.643159Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.585369Z",
          "shell.execute_reply": "2021-05-22T18:24:05.642310Z"
        },
        "trusted": true,
        "id": "g77BTYgcTH-H"
      },
      "source": [
        "def padding_tokens(tokens,pd_tkn):\n",
        "    if(len(tokens)<max_input_length-1):\n",
        "        for i in range(max_input_length-1 -len(tokens)):\n",
        "            tokens.append(pd_tkn)\n",
        "    return tokens\n",
        "\n",
        "label2index = {\"entailment\":0,\"neutral\":1,\"contradiction\":2}\n",
        "\n",
        "train_data = {}\n",
        "train_data['sequence'] = []\n",
        "train_data['attention_mask']=[]\n",
        "train_data['token_type']=[]\n",
        "train_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_train['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#   print(len(token_ids),end=\" \")\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "#   print(len(pd_tokens),end=\" /\")\n",
        "  train_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_train['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  train_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_train['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  train_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_train['gold_label']:\n",
        "    train_data['gold_label'].append(label2index[t])\n",
        "\n",
        "#valid data\n",
        "valid_data = {}\n",
        "valid_data['sequence'] = []\n",
        "valid_data['attention_mask']=[]\n",
        "valid_data['token_type']=[]\n",
        "valid_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_dev['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  valid_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_dev['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  valid_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_dev['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  valid_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_dev['gold_label']:\n",
        "    valid_data['gold_label'].append(label2index[t])\n",
        "\n",
        "test_data = {}\n",
        "test_data['sequence'] = []\n",
        "test_data['attention_mask']=[]\n",
        "test_data['token_type']=[]\n",
        "test_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_test['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  test_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_test['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  test_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_test['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  test_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_test['gold_label']:\n",
        "    test_data['gold_label'].append(label2index[t])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:11.701745Z",
          "iopub.execute_input": "2021-05-22T18:24:11.702103Z",
          "iopub.status.idle": "2021-05-22T18:24:11.731022Z",
          "shell.execute_reply.started": "2021-05-22T18:24:11.702072Z",
          "shell.execute_reply": "2021-05-22T18:24:11.730049Z"
        },
        "trusted": true,
        "id": "V25Nf2FZTH-M"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def getDataloader(dataset):\n",
        "    # print(len(dataset[\"premise\"]))\n",
        "    # for i in dataset[\"sequence\"][:100]:\n",
        "    #     print(len(i),end=\" \")\n",
        "    sequence = torch.tensor(dataset[\"sequence\"],dtype=torch.long)\n",
        "    attention_mask = torch.tensor(dataset[\"attention_mask\"],dtype=torch.long)\n",
        "    token_type = torch.tensor(dataset[\"token_type\"],dtype=torch.long)\n",
        "    labels = torch.tensor(dataset[\"gold_label\"],dtype=torch.long)\n",
        "    dataset = torch.utils.data.TensorDataset(sequence,attention_mask,token_type,labels)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    return dataloader\n",
        "  \n",
        "train_dataloader = getDataloader(train_data)\n",
        "valid_dataloader = getDataloader(valid_data)\n",
        "test_dataloader = getDataloader(test_data)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:11.732527Z",
          "iopub.execute_input": "2021-05-22T18:24:11.733192Z",
          "iopub.status.idle": "2021-05-22T18:24:36.845015Z",
          "shell.execute_reply.started": "2021-05-22T18:24:11.733148Z",
          "shell.execute_reply": "2021-05-22T18:24:36.844145Z"
        },
        "trusted": true,
        "id": "EssWp8iUTH-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aae2b04-9230-4c0a-80a2-00f732ccf8ec"
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:36.855932Z",
          "iopub.execute_input": "2021-05-22T18:24:36.856437Z",
          "iopub.status.idle": "2021-05-22T18:24:36.866563Z",
          "shell.execute_reply.started": "2021-05-22T18:24:36.856399Z",
          "shell.execute_reply": "2021-05-22T18:24:36.865841Z"
        },
        "trusted": true,
        "id": "VDo0_WcrTH-N"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTNLIModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert_model,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                ):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert_model\n",
        "        \n",
        "        embedding_dim = bert_model.config.to_dict()['hidden_size']\n",
        "        self.out = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "    def forward(self, sequence, attn_mask, token_type):\n",
        "        embedded = self.bert(input_ids = sequence, attention_mask = attn_mask, token_type_ids= token_type)[1]\n",
        "        output = self.out(embedded)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:36.867698Z",
          "iopub.execute_input": "2021-05-22T18:24:36.868235Z",
          "iopub.status.idle": "2021-05-22T18:24:41.276060Z",
          "shell.execute_reply.started": "2021-05-22T18:24:36.868195Z",
          "shell.execute_reply": "2021-05-22T18:24:41.275145Z"
        },
        "trusted": true,
        "id": "jaloK1rXTH-O"
      },
      "source": [
        "HIDDEN_DIM = 512\n",
        "OUTPUT_DIM = len(label2index)\n",
        "\n",
        "model = BERTNLIModel(bert_model,HIDDEN_DIM,OUTPUT_DIM,).to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:41.312320Z",
          "iopub.execute_input": "2021-05-22T18:24:41.312761Z",
          "iopub.status.idle": "2021-05-22T18:24:48.156690Z",
          "shell.execute_reply.started": "2021-05-22T18:24:41.312719Z",
          "shell.execute_reply": "2021-05-22T18:24:48.154976Z"
        },
        "trusted": true,
        "id": "xWHcwbEuTH-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963b23e8-79de-4a73-fb17-486addf2f121"
      },
      "source": [
        "from transformers import *"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:48.158473Z",
          "iopub.execute_input": "2021-05-22T18:24:48.158884Z",
          "iopub.status.idle": "2021-05-22T18:24:48.170838Z",
          "shell.execute_reply.started": "2021-05-22T18:24:48.158822Z",
          "shell.execute_reply": "2021-05-22T18:24:48.167735Z"
        },
        "trusted": true,
        "id": "zcpOWOTdTH-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742b18c4-57ba-4dff-a656-d47c9614bd0a"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters())\n",
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-6,correct_bias=False)\n",
        "\n",
        "def get_scheduler(optimizer, warmup_steps):\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "    return scheduler"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:48.172358Z",
          "iopub.execute_input": "2021-05-22T18:24:48.172752Z",
          "iopub.status.idle": "2021-05-22T18:24:49.688801Z",
          "shell.execute_reply.started": "2021-05-22T18:24:48.172711Z",
          "shell.execute_reply": "2021-05-22T18:24:49.687709Z"
        },
        "trusted": true,
        "id": "o1oS_9oNTH-Q"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:49.690480Z",
          "iopub.execute_input": "2021-05-22T18:24:49.691979Z",
          "iopub.status.idle": "2021-05-22T18:24:49.700224Z",
          "shell.execute_reply.started": "2021-05-22T18:24:49.691928Z",
          "shell.execute_reply": "2021-05-22T18:24:49.699269Z"
        },
        "trusted": true,
        "id": "oWYJmI66TH-Q"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = (max_preds.squeeze(1)==y).float()\n",
        "    return correct.sum() / len(y)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:51.141635Z",
          "iopub.execute_input": "2021-05-22T18:24:51.141968Z",
          "iopub.status.idle": "2021-05-22T18:24:51.152037Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.141934Z",
          "shell.execute_reply": "2021-05-22T18:24:51.151084Z"
        },
        "trusted": true,
        "id": "LGxOjwjkTH-Q"
      },
      "source": [
        "max_grad_norm = 1\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, scheduler):\n",
        "    #print(iterator)\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for sequence,attn_mask,token_type,label in tqdm(iterator):\n",
        "\n",
        "        optimizer.zero_grad() # clear gradients first\n",
        "        torch.cuda.empty_cache() # releases all unoccupied cached memory \n",
        "        \n",
        "        sequence,attn_mask,token_type,label = sequence.to(device),attn_mask.to(device),token_type.to(device),label.to(device)\n",
        "        \n",
        "        predictions = model(sequence, attn_mask, token_type)\n",
        "        \n",
        "        loss = criterion(predictions, label)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, label)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:51.153318Z",
          "iopub.execute_input": "2021-05-22T18:24:51.153732Z",
          "iopub.status.idle": "2021-05-22T18:24:51.166942Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.153685Z",
          "shell.execute_reply": "2021-05-22T18:24:51.166060Z"
        },
        "trusted": true,
        "id": "PjPxruc3TH-R"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    #print(iterator)\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for sequence,attn_mask,token_type,labels in tqdm(iterator):\n",
        "\n",
        "            sequence,attn_mask,token_type,labels = sequence.to(device),attn_mask.to(device),token_type.to(device),labels.to(device)\n",
        "            predictions = model(sequence, attn_mask, token_type)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "                \n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:51.169166Z",
          "iopub.execute_input": "2021-05-22T18:24:51.170246Z",
          "iopub.status.idle": "2021-05-22T18:24:51.181751Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.170216Z",
          "shell.execute_reply": "2021-05-22T18:24:51.181031Z"
        },
        "trusted": true,
        "id": "xIoYct0uTH-R"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T18:24:51.183111Z",
          "iopub.execute_input": "2021-05-22T18:24:51.183483Z",
          "iopub.status.idle": "2021-05-22T19:43:27.258977Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.183445Z",
          "shell.execute_reply": "2021-05-22T19:43:27.257798Z"
        },
        "trusted": true,
        "id": "36KbCzW2TH-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96182d98-011d-4305-812a-22b2cc30d2e3"
      },
      "source": [
        "import math\n",
        "N_EPOCHS = 6\n",
        "\n",
        "warmup_percent = 0.2\n",
        "total_steps = math.ceil(N_EPOCHS*train_data_len*1./BATCH_SIZE)\n",
        "warmup_steps = int(total_steps*warmup_percent)\n",
        "scheduler = get_scheduler(optimizer, warmup_steps)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "best_epoch=0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, scheduler)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_epoch=epoch\n",
        "    torch.save(model.state_dict(), f'/content/gdrive/MyDrive/NLPProject/models/bert-nli_{epoch}.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:48<00:00,  4.72it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 9m 3s\n",
            "\tTrain Loss: 0.639 | Train Acc: 72.14%\n",
            "\t Val. Loss: 0.341 |  Val. Acc: 87.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:51<00:00,  4.70it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 16.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02 | Epoch Time: 9m 5s\n",
            "\tTrain Loss: 0.377 | Train Acc: 85.92%\n",
            "\t Val. Loss: 0.208 |  Val. Acc: 93.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:50<00:00,  4.71it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 16.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03 | Epoch Time: 9m 5s\n",
            "\tTrain Loss: 0.240 | Train Acc: 91.65%\n",
            "\t Val. Loss: 0.107 |  Val. Acc: 96.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:51<00:00,  4.70it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 17.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04 | Epoch Time: 9m 5s\n",
            "\tTrain Loss: 0.162 | Train Acc: 94.57%\n",
            "\t Val. Loss: 0.065 |  Val. Acc: 98.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:51<00:00,  4.70it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 17.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05 | Epoch Time: 9m 5s\n",
            "\tTrain Loss: 0.117 | Train Acc: 96.25%\n",
            "\t Val. Loss: 0.048 |  Val. Acc: 98.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2498/2498 [08:50<00:00,  4.71it/s]\n",
            "100%|██████████| 250/250 [00:14<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06 | Epoch Time: 9m 4s\n",
            "\tTrain Loss: 0.089 | Train Acc: 97.14%\n",
            "\t Val. Loss: 0.031 |  Val. Acc: 99.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:27.263388Z",
          "iopub.execute_input": "2021-05-22T19:43:27.265736Z",
          "iopub.status.idle": "2021-05-22T19:43:39.283837Z",
          "shell.execute_reply.started": "2021-05-22T19:43:27.265691Z",
          "shell.execute_reply": "2021-05-22T19:43:39.282313Z"
        },
        "trusted": true,
        "id": "-pTN9d9BTH-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23775a18-d11a-4142-8731-0077a3e2e5d3"
      },
      "source": [
        "model.load_state_dict(torch.load(f'/content/gdrive/MyDrive/NLPProject/models/bert-nli_{best_epoch}.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:14<00:00, 16.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.031 |  Test Acc: 99.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.285211Z",
          "iopub.execute_input": "2021-05-22T19:43:39.285573Z",
          "iopub.status.idle": "2021-05-22T19:43:39.293377Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.285534Z",
          "shell.execute_reply": "2021-05-22T19:43:39.292238Z"
        },
        "trusted": true,
        "id": "clPjVrsVTH-S"
      },
      "source": [
        "index2label={0:\"entailment\",1:\"neutral\",2:\"contradiction\"}\n",
        "def predict_inference(premise, hypothesis, model, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    premise = '[CLS] ' + premise + ' [SEP]'\n",
        "    hypothesis = hypothesis + ' [SEP]'\n",
        "    \n",
        "    prem_t = tokenize_bert(premise)\n",
        "    hypo_t = tokenize_bert(hypothesis)\n",
        "    \n",
        "    #print(len(prem_t), len(hypo_t))\n",
        "    \n",
        "    prem_type = get_sent1_token_type(prem_t)\n",
        "    hypo_type = get_sent2_token_type(hypo_t)\n",
        "    \n",
        "    #print(len(prem_type), len(hypo_type))\n",
        "    \n",
        "    indexes = prem_t + hypo_t\n",
        "    \n",
        "    indexes = tokenizer.convert_tokens_to_ids(indexes)\n",
        "    #print(indexes)\n",
        "    indexes_type = prem_type + hypo_type\n",
        "    #print(indexes_type)\n",
        "    \n",
        "    attn_mask = get_sent2_token_type(indexes)\n",
        "    #print(attn_mask)\n",
        "    \n",
        "    #print(len(indexes))\n",
        "    #print(len(indexes_type))\n",
        "    #print(len(attn_mask))\n",
        "\n",
        "    #seq = '[CLS] '+ premise + ' [SEP] '+ hypothesis \n",
        "\n",
        "    #tokens = tokenizer.tokenize(seq)\n",
        "\n",
        "    #indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    indexes = torch.LongTensor(indexes).unsqueeze(0).to(device)\n",
        "    indexes_type = torch.LongTensor(indexes_type).unsqueeze(0).to(device)\n",
        "    attn_mask = torch.LongTensor(attn_mask).unsqueeze(0).to(device)\n",
        "    \n",
        "    #print(indexes.size())\n",
        "    \n",
        "    prediction = model(indexes, attn_mask, indexes_type)\n",
        "    \n",
        "    prediction = prediction.argmax(dim=-1).item()\n",
        "    \n",
        "    return index2label[prediction]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.294655Z",
          "iopub.execute_input": "2021-05-22T19:43:39.295190Z",
          "iopub.status.idle": "2021-05-22T19:43:39.345334Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.295145Z",
          "shell.execute_reply": "2021-05-22T19:43:39.344616Z"
        },
        "trusted": true,
        "id": "Hxb5rikYTH-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e3a5000-1d26-4ee0-f6b3-ec61e52b942b"
      },
      "source": [
        "premise = 'a man sitting on a green bench.'\n",
        "hypothesis = 'a woman sitting on a green bench.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.346465Z",
          "iopub.execute_input": "2021-05-22T19:43:39.346775Z",
          "iopub.status.idle": "2021-05-22T19:43:39.382134Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.346742Z",
          "shell.execute_reply": "2021-05-22T19:43:39.381216Z"
        },
        "trusted": true,
        "id": "2I-cDRfXTH-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dbbf6a98-f594-4880-955a-9a0f3b452f27"
      },
      "source": [
        "premise = 'a man sitting on a green bench.'\n",
        "hypothesis = 'a man sitting on a blue bench.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.383222Z",
          "iopub.execute_input": "2021-05-22T19:43:39.383665Z",
          "iopub.status.idle": "2021-05-22T19:43:39.421339Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.383628Z",
          "shell.execute_reply": "2021-05-22T19:43:39.420435Z"
        },
        "trusted": true,
        "id": "blZecUUDTH-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf2148df-a960-437b-fb53-8043996e4612"
      },
      "source": [
        "premise = 'I am lying down on bed.'\n",
        "hypothesis = 'I am resting on bed.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'entailment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.422429Z",
          "iopub.execute_input": "2021-05-22T19:43:39.422755Z",
          "iopub.status.idle": "2021-05-22T19:43:39.458545Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.422722Z",
          "shell.execute_reply": "2021-05-22T19:43:39.457617Z"
        },
        "trusted": true,
        "id": "Ra1Ex97jTH-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81b76fd9-b94a-4419-c53f-cb240ef6e6b2"
      },
      "source": [
        "premise = 'I go to office on my personal car.'\n",
        "hypothesis = 'I have to share office cab for reaching office.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.459640Z",
          "iopub.execute_input": "2021-05-22T19:43:39.459985Z",
          "iopub.status.idle": "2021-05-22T19:43:39.498287Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.459951Z",
          "shell.execute_reply": "2021-05-22T19:43:39.497356Z"
        },
        "trusted": true,
        "id": "j9Y0i_1xTH-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9925f7ae-6b76-46db-dfd3-81c80a0d0b2d"
      },
      "source": [
        "premise = 'I love to play cricket.'\n",
        "hypothesis = 'I enjoy playing football.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.499376Z",
          "iopub.execute_input": "2021-05-22T19:43:39.499708Z",
          "iopub.status.idle": "2021-05-22T19:43:39.537532Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.499675Z",
          "shell.execute_reply": "2021-05-22T19:43:39.536636Z"
        },
        "trusted": true,
        "id": "K8_YE-R5TH-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cf69fdd-592c-47aa-dd78-c11948fb3300"
      },
      "source": [
        "premise = 'He is techy.'\n",
        "hypothesis = 'He has no idea of tech.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'contradiction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-05-22T19:43:39.538597Z",
          "iopub.execute_input": "2021-05-22T19:43:39.539065Z",
          "iopub.status.idle": "2021-05-22T19:43:39.585624Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.539029Z",
          "shell.execute_reply": "2021-05-22T19:43:39.584727Z"
        },
        "trusted": true,
        "id": "lhFq0CRcTH-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb2190c2-1a36-425c-db59-fc8c076a1244"
      },
      "source": [
        "premise = 'I am using mobile phone.'\n",
        "hypothesis = 'I have mobile in my hand.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'entailment'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ1wOHoITH-V"
      },
      "source": [],
      "execution_count": 54,
      "outputs": []
    }
  ]
}