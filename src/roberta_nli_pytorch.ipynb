{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xlmN_2TH95"
      },
      "source": [
        "# Setting Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6eOgkbETM4r"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:36.396768Z",
          "iopub.status.busy": "2021-05-22T18:22:36.396454Z",
          "iopub.status.idle": "2021-05-22T18:22:36.412405Z",
          "shell.execute_reply": "2021-05-22T18:22:36.411362Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.396741Z"
        },
        "id": "ZYRlkywfTH98",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyqsMcL6TH98"
      },
      "source": [
        "# Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:36.414320Z",
          "iopub.status.busy": "2021-05-22T18:22:36.413926Z",
          "iopub.status.idle": "2021-05-22T18:22:36.738700Z",
          "shell.execute_reply": "2021-05-22T18:22:36.737913Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.414279Z"
        },
        "id": "jUiwn5QfTH99",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "SEED = 1111\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:36.741342Z",
          "iopub.status.busy": "2021-05-22T18:22:36.741101Z",
          "iopub.status.idle": "2021-05-22T18:22:39.816045Z",
          "shell.execute_reply": "2021-05-22T18:22:39.815184Z",
          "shell.execute_reply.started": "2021-05-22T18:22:36.741317Z"
        },
        "id": "A6fmllOKTH99",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_name='roberta-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.848458Z",
          "iopub.status.busy": "2021-05-22T18:22:39.847826Z",
          "iopub.status.idle": "2021-05-22T18:22:39.856324Z",
          "shell.execute_reply": "2021-05-22T18:22:39.855337Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.848417Z"
        },
        "id": "dmwYflD8TH9-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.858605Z",
          "iopub.status.busy": "2021-05-22T18:22:39.857905Z",
          "iopub.status.idle": "2021-05-22T18:22:39.865416Z",
          "shell.execute_reply": "2021-05-22T18:22:39.864368Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.858568Z"
        },
        "id": "qUcbVwr2TH9_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.867411Z",
          "iopub.status.busy": "2021-05-22T18:22:39.866788Z",
          "iopub.status.idle": "2021-05-22T18:22:39.875804Z",
          "shell.execute_reply": "2021-05-22T18:22:39.874848Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.867372Z"
        },
        "id": "fHo--jhxTH9_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[model_name]\n",
        "\n",
        "print(max_input_length)\n",
        "\n",
        "max_input_length = 63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.877717Z",
          "iopub.status.busy": "2021-05-22T18:22:39.877189Z",
          "iopub.status.idle": "2021-05-22T18:22:39.884514Z",
          "shell.execute_reply": "2021-05-22T18:22:39.883641Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.877674Z"
        },
        "id": "83VWXLVLTH-A",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tokenize_bert(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.886398Z",
          "iopub.status.busy": "2021-05-22T18:22:39.885989Z",
          "iopub.status.idle": "2021-05-22T18:22:39.894256Z",
          "shell.execute_reply": "2021-05-22T18:22:39.893338Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.886361Z"
        },
        "id": "DYvGYvORTH-A",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def split_and_cut(sentence):\n",
        "    tokens = sentence.strip().split(\" \")\n",
        "    tokens = tokens[:max_input_length-1]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.896302Z",
          "iopub.status.busy": "2021-05-22T18:22:39.895637Z",
          "iopub.status.idle": "2021-05-22T18:22:39.904166Z",
          "shell.execute_reply": "2021-05-22T18:22:39.903403Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.896263Z"
        },
        "id": "6K4QtCsQTH-A",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def trim_sentence(sent):\n",
        "    try:\n",
        "        sent = sent.split()\n",
        "        sent = sent[:32]\n",
        "        return \" \".join(sent)\n",
        "    except:\n",
        "        return sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHqpAXipTH-B"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:39.906075Z",
          "iopub.status.busy": "2021-05-22T18:22:39.905621Z",
          "iopub.status.idle": "2021-05-22T18:22:51.266832Z",
          "shell.execute_reply": "2021-05-22T18:22:51.265794Z",
          "shell.execute_reply.started": "2021-05-22T18:22:39.906039Z"
        },
        "id": "GI2wzJciTH-B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:51.270159Z",
          "iopub.status.busy": "2021-05-22T18:22:51.269742Z",
          "iopub.status.idle": "2021-05-22T18:22:54.896800Z",
          "shell.execute_reply": "2021-05-22T18:22:54.895335Z",
          "shell.execute_reply.started": "2021-05-22T18:22:51.270112Z"
        },
        "id": "hclFoPKmTH-B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "  \n",
        "# specifying the zip file name\n",
        "file_name = \"snli_1.0.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "  \n",
        "    # extracting all the files\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9_msVLYTH-C"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:22:54.898549Z",
          "iopub.status.busy": "2021-05-22T18:22:54.898199Z",
          "iopub.status.idle": "2021-05-22T18:22:54.904679Z",
          "shell.execute_reply": "2021-05-22T18:22:54.903657Z",
          "shell.execute_reply.started": "2021-05-22T18:22:54.898514Z"
        },
        "id": "J1lTSBY2TH-C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_sent1_token_type(sent):\n",
        "    try:\n",
        "        return [0]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def get_sent2_token_type(sent):\n",
        "    try:\n",
        "        return [1]* len(sent)\n",
        "    except:\n",
        "        return []\n",
        "    \n",
        "def combine_seq(seq):\n",
        "    return \" \".join(seq)\n",
        "\n",
        "def combine_mask(mask):\n",
        "    mask = [str(m) for m in mask]\n",
        "    return \" \".join(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o_OB1lsTowj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('snli_1.0/snli_1.0_train.txt', sep='\\t')\n",
        "df_dev = pd.read_csv('snli_1.0/snli_1.0_dev.txt', sep='\\t')\n",
        "df_test = pd.read_csv('snli_1.0/snli_1.0_test.txt', sep='\\t')\n",
        "\n",
        "df_train = df_train[['gold_label','sentence1','sentence2']]\n",
        "df_dev = df_dev[['gold_label','sentence1','sentence2']]\n",
        "df_test = df_test[['gold_label','sentence1','sentence2']]\n",
        "\n",
        "df_train = df_train[:40000]\n",
        "df_dev = df_dev[:4000]\n",
        "df_test = df_test[:4000]\n",
        "CLS=init_token\n",
        "SEP=eos_token\n",
        "\n",
        "df_train['sentence1'] = df_train['sentence1'].apply(trim_sentence)\n",
        "df_train['sentence2'] = df_train['sentence2'].apply(trim_sentence)\n",
        "df_dev['sentence1'] = df_dev['sentence1'].apply(trim_sentence)\n",
        "df_dev['sentence2'] = df_dev['sentence2'].apply(trim_sentence)\n",
        "df_test['sentence1'] = df_test['sentence1'].apply(trim_sentence)\n",
        "df_test['sentence2'] = df_test['sentence2'].apply(trim_sentence)\n",
        "\n",
        "df_train['sent1'] = f'{CLS} ' + df_train['sentence1'] + f' {SEP} '\n",
        "df_train['sent2'] = df_train['sentence2'] + f' {SEP}'\n",
        "df_dev['sent1'] = f'{CLS} ' + df_dev['sentence1'] + f' {SEP} '\n",
        "df_dev['sent2'] = df_dev['sentence2'] + f' {SEP}'\n",
        "df_test['sent1'] = f'{CLS} ' + df_test['sentence1'] + f' {SEP} '\n",
        "df_test['sent2'] = df_test['sentence2'] + f' {SEP}'\n",
        "\n",
        "df_train['sent1_t'] = df_train['sent1'].apply(tokenize_bert)\n",
        "df_train['sent2_t'] = df_train['sent2'].apply(tokenize_bert)\n",
        "df_dev['sent1_t'] = df_dev['sent1'].apply(tokenize_bert)\n",
        "df_dev['sent2_t'] = df_dev['sent2'].apply(tokenize_bert)\n",
        "df_test['sent1_t'] = df_test['sent1'].apply(tokenize_bert)\n",
        "df_test['sent2_t'] = df_test['sent2'].apply(tokenize_bert)\n",
        "\n",
        "df_train['sent1_token_type'] = df_train['sent1_t'].apply(get_sent1_token_type)\n",
        "df_train['sent2_token_type'] = df_train['sent2_t'].apply(get_sent2_token_type)\n",
        "df_dev['sent1_token_type'] = df_dev['sent1_t'].apply(get_sent1_token_type)\n",
        "df_dev['sent2_token_type'] = df_dev['sent2_t'].apply(get_sent2_token_type)\n",
        "df_test['sent1_token_type'] = df_test['sent1_t'].apply(get_sent1_token_type)\n",
        "df_test['sent2_token_type'] = df_test['sent2_t'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['sequence'] = df_train['sent1_t'] + df_train['sent2_t']\n",
        "df_dev['sequence'] = df_dev['sent1_t'] + df_dev['sent2_t']\n",
        "df_test['sequence'] = df_test['sent1_t'] + df_test['sent2_t']\n",
        "\n",
        "\n",
        "df_train['attention_mask'] = df_train['sequence'].apply(get_sent2_token_type)\n",
        "df_dev['attention_mask'] = df_dev['sequence'].apply(get_sent2_token_type)\n",
        "df_test['attention_mask'] = df_test['sequence'].apply(get_sent2_token_type)\n",
        "\n",
        "df_train['token_type'] = df_train['sent1_token_type'] + df_train['sent2_token_type']\n",
        "df_dev['token_type'] = df_dev['sent1_token_type'] + df_dev['sent2_token_type']\n",
        "df_test['token_type'] = df_test['sent1_token_type'] + df_test['sent2_token_type']\n",
        "\n",
        "df_train['sequence'] = df_train['sequence'].apply(combine_seq)\n",
        "df_dev['sequence'] = df_dev['sequence'].apply(combine_seq)\n",
        "df_test['sequence'] = df_test['sequence'].apply(combine_seq)\n",
        "\n",
        "df_train['attention_mask'] = df_train['attention_mask'].apply(combine_mask)\n",
        "df_dev['attention_mask'] = df_dev['attention_mask'].apply(combine_mask)\n",
        "df_test['attention_mask'] = df_test['attention_mask'].apply(combine_mask)\n",
        "\n",
        "df_train['token_type'] = df_train['token_type'].apply(combine_mask)\n",
        "df_dev['token_type'] = df_dev['token_type'].apply(combine_mask)\n",
        "df_test['token_type'] = df_test['token_type'].apply(combine_mask)\n",
        "\n",
        "df_train = df_train[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_dev = df_dev[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "df_test = df_test[['gold_label', 'sequence', 'attention_mask', 'token_type']]\n",
        "\n",
        "\n",
        "\n",
        "df_train = df_train.loc[df_train['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "df_dev = df_dev.loc[df_dev['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "df_test = df_test.loc[df_test['gold_label'].isin(['entailment','contradiction','neutral'])]\n",
        "\n",
        "\n",
        "\n",
        "df_train.to_csv('snli_1.0/snli_1.0_train.csv', index=False)\n",
        "df_dev.to_csv('snli_1.0/snli_1.0_dev.csv', index=False)\n",
        "df_test.to_csv('snli_1.0/snli_1.0_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:05.517130Z",
          "iopub.status.busy": "2021-05-22T18:24:05.516834Z",
          "iopub.status.idle": "2021-05-22T18:24:05.523940Z",
          "shell.execute_reply": "2021-05-22T18:24:05.523027Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.517103Z"
        },
        "id": "Lmiw-NSBTH-F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(df_train.iloc[0]['sequence'])\n",
        "print(df_train.iloc[0]['attention_mask'])\n",
        "print(df_train.iloc[0]['token_type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:05.548321Z",
          "iopub.status.busy": "2021-05-22T18:24:05.547967Z",
          "iopub.status.idle": "2021-05-22T18:24:05.553413Z",
          "shell.execute_reply": "2021-05-22T18:24:05.552328Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.548287Z"
        },
        "id": "LoERk9gXTH-G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:05.572040Z",
          "iopub.status.busy": "2021-05-22T18:24:05.571467Z",
          "iopub.status.idle": "2021-05-22T18:24:05.582200Z",
          "shell.execute_reply": "2021-05-22T18:24:05.581378Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.571999Z"
        },
        "id": "jRapwGZtTH-H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def convert_to_int(tok_ids):\n",
        "    tok_ids = [int(x) for x in tok_ids]\n",
        "    return tok_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:05.585410Z",
          "iopub.status.busy": "2021-05-22T18:24:05.584732Z",
          "iopub.status.idle": "2021-05-22T18:24:05.643159Z",
          "shell.execute_reply": "2021-05-22T18:24:05.642310Z",
          "shell.execute_reply.started": "2021-05-22T18:24:05.585369Z"
        },
        "id": "g77BTYgcTH-H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def padding_tokens(tokens,pd_tkn):\n",
        "    if(len(tokens)<max_input_length-1):\n",
        "        for i in range(max_input_length-1 -len(tokens)):\n",
        "            tokens.append(pd_tkn)\n",
        "    return tokens\n",
        "\n",
        "label2index = {\"entailment\":0,\"neutral\":1,\"contradiction\":2}\n",
        "\n",
        "train_data = {}\n",
        "train_data['sequence'] = []\n",
        "train_data['attention_mask']=[]\n",
        "train_data['token_type']=[]\n",
        "train_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_train['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "#   print(len(token_ids),end=\" \")\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "#   print(len(pd_tokens),end=\" /\")\n",
        "  train_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_train['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  train_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_train['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  train_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_train['gold_label']:\n",
        "    train_data['gold_label'].append(label2index[t])\n",
        "\n",
        "#valid data\n",
        "valid_data = {}\n",
        "valid_data['sequence'] = []\n",
        "valid_data['attention_mask']=[]\n",
        "valid_data['token_type']=[]\n",
        "valid_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_dev['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  valid_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_dev['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  valid_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_dev['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  valid_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_dev['gold_label']:\n",
        "    valid_data['gold_label'].append(label2index[t])\n",
        "\n",
        "test_data = {}\n",
        "test_data['sequence'] = []\n",
        "test_data['attention_mask']=[]\n",
        "test_data['token_type']=[]\n",
        "test_data['gold_label']=[]\n",
        "\n",
        "for data_t in df_test['sequence']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  test_data['sequence'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_test['attention_mask']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,pad_token_idx)\n",
        "  test_data['attention_mask'].append(pd_tokens)\n",
        "\n",
        "for data_t in df_test['token_type']:\n",
        "  tokens = split_and_cut(data_t)\n",
        "  token_ids = convert_to_int(tokens)\n",
        "  pd_tokens = padding_tokens(token_ids,1)\n",
        "  test_data['token_type'].append(pd_tokens)\n",
        "\n",
        "for t in df_test['gold_label']:\n",
        "    test_data['gold_label'].append(label2index[t])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:11.702103Z",
          "iopub.status.busy": "2021-05-22T18:24:11.701745Z",
          "iopub.status.idle": "2021-05-22T18:24:11.731022Z",
          "shell.execute_reply": "2021-05-22T18:24:11.730049Z",
          "shell.execute_reply.started": "2021-05-22T18:24:11.702072Z"
        },
        "id": "V25Nf2FZTH-M",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def getDataloader(dataset):\n",
        "    # print(len(dataset[\"premise\"]))\n",
        "    # for i in dataset[\"sequence\"][:100]:\n",
        "    #     print(len(i),end=\" \")\n",
        "    sequence = torch.tensor(dataset[\"sequence\"],dtype=torch.long)\n",
        "    attention_mask = torch.tensor(dataset[\"attention_mask\"],dtype=torch.long)\n",
        "    token_type = torch.tensor(dataset[\"token_type\"],dtype=torch.long)\n",
        "    labels = torch.tensor(dataset[\"gold_label\"],dtype=torch.long)\n",
        "    dataset = torch.utils.data.TensorDataset(sequence,attention_mask,token_type,labels)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    return dataloader\n",
        "  \n",
        "train_dataloader = getDataloader(train_data)\n",
        "valid_dataloader = getDataloader(valid_data)\n",
        "test_dataloader = getDataloader(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:11.733192Z",
          "iopub.status.busy": "2021-05-22T18:24:11.732527Z",
          "iopub.status.idle": "2021-05-22T18:24:36.845015Z",
          "shell.execute_reply": "2021-05-22T18:24:36.844145Z",
          "shell.execute_reply.started": "2021-05-22T18:24:11.733148Z"
        },
        "id": "EssWp8iUTH-N",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(model_name,output_hidden_states=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:36.856437Z",
          "iopub.status.busy": "2021-05-22T18:24:36.855932Z",
          "iopub.status.idle": "2021-05-22T18:24:36.866563Z",
          "shell.execute_reply": "2021-05-22T18:24:36.865841Z",
          "shell.execute_reply.started": "2021-05-22T18:24:36.856399Z"
        },
        "id": "VDo0_WcrTH-N",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTNLIModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert_model,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                ):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert_model\n",
        "        \n",
        "        embedding_dim = bert_model.config.hidden_size\n",
        "\n",
        "        self.out = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "        \n",
        "    def forward(self, sequence, attn_mask, token_type):\n",
        "        \n",
        "                \n",
        "        embedded = self.bert(input_ids = sequence, attention_mask = attn_mask, token_type_ids= token_type)[1]    \n",
        "        \n",
        "        output = self.out(embedded)\n",
        "\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:36.868235Z",
          "iopub.status.busy": "2021-05-22T18:24:36.867698Z",
          "iopub.status.idle": "2021-05-22T18:24:41.276060Z",
          "shell.execute_reply": "2021-05-22T18:24:41.275145Z",
          "shell.execute_reply.started": "2021-05-22T18:24:36.868195Z"
        },
        "id": "jaloK1rXTH-O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "HIDDEN_DIM = 512\n",
        "OUTPUT_DIM = len(label2index)\n",
        "\n",
        "model = BERTNLIModel(bert_model,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                        ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:41.312761Z",
          "iopub.status.busy": "2021-05-22T18:24:41.312320Z",
          "iopub.status.idle": "2021-05-22T18:24:48.156690Z",
          "shell.execute_reply": "2021-05-22T18:24:48.154976Z",
          "shell.execute_reply.started": "2021-05-22T18:24:41.312719Z"
        },
        "id": "xWHcwbEuTH-P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:48.158884Z",
          "iopub.status.busy": "2021-05-22T18:24:48.158473Z",
          "iopub.status.idle": "2021-05-22T18:24:48.170838Z",
          "shell.execute_reply": "2021-05-22T18:24:48.167735Z",
          "shell.execute_reply.started": "2021-05-22T18:24:48.158822Z"
        },
        "id": "zcpOWOTdTH-P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#optimizer = optim.Adam(model.parameters())\n",
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-6,correct_bias=False)\n",
        "\n",
        "def get_scheduler(optimizer, warmup_steps):\n",
        "    scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
        "    return scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:48.172752Z",
          "iopub.status.busy": "2021-05-22T18:24:48.172358Z",
          "iopub.status.idle": "2021-05-22T18:24:49.688801Z",
          "shell.execute_reply": "2021-05-22T18:24:49.687709Z",
          "shell.execute_reply.started": "2021-05-22T18:24:48.172711Z"
        },
        "id": "o1oS_9oNTH-Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:49.691979Z",
          "iopub.status.busy": "2021-05-22T18:24:49.690480Z",
          "iopub.status.idle": "2021-05-22T18:24:49.700224Z",
          "shell.execute_reply": "2021-05-22T18:24:49.699269Z",
          "shell.execute_reply.started": "2021-05-22T18:24:49.691928Z"
        },
        "id": "oWYJmI66TH-Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = (max_preds.squeeze(1)==y).float()\n",
        "    return correct.sum() / len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:51.141968Z",
          "iopub.status.busy": "2021-05-22T18:24:51.141635Z",
          "iopub.status.idle": "2021-05-22T18:24:51.152037Z",
          "shell.execute_reply": "2021-05-22T18:24:51.151084Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.141934Z"
        },
        "id": "LGxOjwjkTH-Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_grad_norm = 1\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, scheduler):\n",
        "    #print(iterator)\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for sequence,attn_mask,token_type,label in tqdm(iterator):\n",
        "\n",
        "        optimizer.zero_grad() # clear gradients first\n",
        "        torch.cuda.empty_cache() # releases all unoccupied cached memory \n",
        "        \n",
        "        sequence,attn_mask,token_type,label = sequence.to(device),attn_mask.to(device),token_type.to(device),label.to(device)\n",
        "        \n",
        "        predictions = model(sequence, attn_mask, token_type)\n",
        "        \n",
        "        \n",
        "        loss = criterion(predictions, label)\n",
        "        \n",
        "        acc = categorical_accuracy(predictions, label)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:51.153732Z",
          "iopub.status.busy": "2021-05-22T18:24:51.153318Z",
          "iopub.status.idle": "2021-05-22T18:24:51.166942Z",
          "shell.execute_reply": "2021-05-22T18:24:51.166060Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.153685Z"
        },
        "id": "PjPxruc3TH-R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    #print(iterator)\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for sequence,attn_mask,token_type,labels in tqdm(iterator):\n",
        "            sequence,attn_mask,token_type,labels = sequence.to(device),attn_mask.to(device),token_type.to(device),labels.to(device)\n",
        "            predictions = model(sequence, attn_mask, token_type)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "                \n",
        "            acc = categorical_accuracy(predictions, labels)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:51.170246Z",
          "iopub.status.busy": "2021-05-22T18:24:51.169166Z",
          "iopub.status.idle": "2021-05-22T18:24:51.181751Z",
          "shell.execute_reply": "2021-05-22T18:24:51.181031Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.170216Z"
        },
        "id": "xIoYct0uTH-R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2U1fUSWTH-R",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T18:24:51.183483Z",
          "iopub.status.busy": "2021-05-22T18:24:51.183111Z",
          "iopub.status.idle": "2021-05-22T19:43:27.258977Z",
          "shell.execute_reply": "2021-05-22T19:43:27.257798Z",
          "shell.execute_reply.started": "2021-05-22T18:24:51.183445Z"
        },
        "id": "36KbCzW2TH-S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "N_EPOCHS = 6\n",
        "\n",
        "warmup_percent = 0.2\n",
        "total_steps = math.ceil(N_EPOCHS*len(train_data['sequence'])*1./BATCH_SIZE)\n",
        "warmup_steps = int(total_steps*warmup_percent)\n",
        "scheduler = get_scheduler(optimizer, warmup_steps)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, scheduler)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), f'bert-nli_{epoch}.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:27.265736Z",
          "iopub.status.busy": "2021-05-22T19:43:27.263388Z",
          "iopub.status.idle": "2021-05-22T19:43:39.283837Z",
          "shell.execute_reply": "2021-05-22T19:43:39.282313Z",
          "shell.execute_reply.started": "2021-05-22T19:43:27.265691Z"
        },
        "id": "-pTN9d9BTH-S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('bert-nli.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.285573Z",
          "iopub.status.busy": "2021-05-22T19:43:39.285211Z",
          "iopub.status.idle": "2021-05-22T19:43:39.293377Z",
          "shell.execute_reply": "2021-05-22T19:43:39.292238Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.285534Z"
        },
        "id": "clPjVrsVTH-S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "index2label={0:\"entailment\",1:\"neutral\",2:\"contradiction\"}\n",
        "def predict_inference(premise, hypothesis, model, device):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    premise = '[CLS] ' + premise + ' [SEP]'\n",
        "    hypothesis = hypothesis + ' [SEP]'\n",
        "    \n",
        "    prem_t = tokenize_bert(premise)\n",
        "    hypo_t = tokenize_bert(hypothesis)\n",
        "    \n",
        "    #print(len(prem_t), len(hypo_t))\n",
        "    \n",
        "    prem_type = get_sent1_token_type(prem_t)\n",
        "    hypo_type = get_sent2_token_type(hypo_t)\n",
        "    \n",
        "    #print(len(prem_type), len(hypo_type))\n",
        "    \n",
        "    indexes = prem_t + hypo_t\n",
        "    \n",
        "    indexes = tokenizer.convert_tokens_to_ids(indexes)\n",
        "    #print(indexes)\n",
        "    indexes_type = prem_type + hypo_type\n",
        "    #print(indexes_type)\n",
        "    \n",
        "    attn_mask = get_sent2_token_type(indexes)\n",
        "    #print(attn_mask)\n",
        "    \n",
        "    #print(len(indexes))\n",
        "    #print(len(indexes_type))\n",
        "    #print(len(attn_mask))\n",
        "\n",
        "    #seq = '[CLS] '+ premise + ' [SEP] '+ hypothesis \n",
        "\n",
        "    #tokens = tokenizer.tokenize(seq)\n",
        "\n",
        "    #indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    indexes = torch.LongTensor(indexes).unsqueeze(0).to(device)\n",
        "    indexes_type = torch.LongTensor(indexes_type).unsqueeze(0).to(device)\n",
        "    attn_mask = torch.LongTensor(attn_mask).unsqueeze(0).to(device)\n",
        "    \n",
        "    #print(indexes.size())\n",
        "    \n",
        "    prediction = model(indexes, attn_mask, indexes_type)\n",
        "    \n",
        "    prediction = prediction.argmax(dim=-1).item()\n",
        "    \n",
        "    return index2label[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.295190Z",
          "iopub.status.busy": "2021-05-22T19:43:39.294655Z",
          "iopub.status.idle": "2021-05-22T19:43:39.345334Z",
          "shell.execute_reply": "2021-05-22T19:43:39.344616Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.295145Z"
        },
        "id": "Hxb5rikYTH-T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'a man sitting on a green bench.'\n",
        "hypothesis = 'a woman sitting on a green bench.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.346775Z",
          "iopub.status.busy": "2021-05-22T19:43:39.346465Z",
          "iopub.status.idle": "2021-05-22T19:43:39.382134Z",
          "shell.execute_reply": "2021-05-22T19:43:39.381216Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.346742Z"
        },
        "id": "2I-cDRfXTH-T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'a man sitting on a green bench.'\n",
        "hypothesis = 'a man sitting on a blue bench.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.383665Z",
          "iopub.status.busy": "2021-05-22T19:43:39.383222Z",
          "iopub.status.idle": "2021-05-22T19:43:39.421339Z",
          "shell.execute_reply": "2021-05-22T19:43:39.420435Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.383628Z"
        },
        "id": "blZecUUDTH-U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'I am lying down on bed.'\n",
        "hypothesis = 'I am resting on bed.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.422755Z",
          "iopub.status.busy": "2021-05-22T19:43:39.422429Z",
          "iopub.status.idle": "2021-05-22T19:43:39.458545Z",
          "shell.execute_reply": "2021-05-22T19:43:39.457617Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.422722Z"
        },
        "id": "Ra1Ex97jTH-U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'I go to office on my personal car.'\n",
        "hypothesis = 'I have to share office cab for reaching office.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.459985Z",
          "iopub.status.busy": "2021-05-22T19:43:39.459640Z",
          "iopub.status.idle": "2021-05-22T19:43:39.498287Z",
          "shell.execute_reply": "2021-05-22T19:43:39.497356Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.459951Z"
        },
        "id": "j9Y0i_1xTH-U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'I love to play cricket.'\n",
        "hypothesis = 'I enjoy playing football.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.499708Z",
          "iopub.status.busy": "2021-05-22T19:43:39.499376Z",
          "iopub.status.idle": "2021-05-22T19:43:39.537532Z",
          "shell.execute_reply": "2021-05-22T19:43:39.536636Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.499675Z"
        },
        "id": "K8_YE-R5TH-V",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'He is techy.'\n",
        "hypothesis = 'He has no idea of tech.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-05-22T19:43:39.539065Z",
          "iopub.status.busy": "2021-05-22T19:43:39.538597Z",
          "iopub.status.idle": "2021-05-22T19:43:39.585624Z",
          "shell.execute_reply": "2021-05-22T19:43:39.584727Z",
          "shell.execute_reply.started": "2021-05-22T19:43:39.539029Z"
        },
        "id": "lhFq0CRcTH-V",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "premise = 'I am using mobile phone.'\n",
        "hypothesis = 'I have mobile in my hand.'\n",
        "\n",
        "predict_inference(premise, hypothesis, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ1wOHoITH-V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BHqpAXipTH-B",
        "x9_msVLYTH-C"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
